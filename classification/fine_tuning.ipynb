{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jw/anaconda3/envs/torch2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-12 10:53:06.874945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-12 10:53:06.874968: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-12 10:53:06.874980: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-12 10:53:06.878386: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-12 10:53:07.413796: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"vinai/bertweet-base\", num_labels=2).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration yangezheng--tum-nlp-sexism-socialmedia-balanced-5f6a67b6df4f5ff5\n",
      "Found cached dataset parquet (/home/jw/.cache/huggingface/datasets/yangezheng___parquet/yangezheng--tum-nlp-sexism-socialmedia-balanced-5f6a67b6df4f5ff5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 3/3 [00:00<00:00, 781.45it/s]\n",
      "Using custom data configuration yangezheng--lidiapierre-fr_sexism_labelled-47db41fd986d0b6f\n",
      "Found cached dataset parquet (/home/jw/.cache/huggingface/datasets/yangezheng___parquet/yangezheng--lidiapierre-fr_sexism_labelled-47db41fd986d0b6f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 3/3 [00:00<00:00, 1008.41it/s]\n",
      "Using custom data configuration yangezheng--CMSB-e8830d4b5003421a\n",
      "Found cached dataset parquet (/home/jw/.cache/huggingface/datasets/yangezheng___parquet/yangezheng--CMSB-e8830d4b5003421a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 3/3 [00:00<00:00, 977.31it/s]\n",
      "Using custom data configuration yangezheng--SWSR-SexComment-091c099e9544aa09\n",
      "Found cached dataset parquet (/home/jw/.cache/huggingface/datasets/yangezheng___parquet/yangezheng--SWSR-SexComment-091c099e9544aa09/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 3/3 [00:00<00:00, 1227.84it/s]\n",
      "Using custom data configuration yangezheng--SWSR-SexWeibo-662f61ce073ea221\n",
      "Found cached dataset parquet (/home/jw/.cache/huggingface/datasets/yangezheng___parquet/yangezheng--SWSR-SexWeibo-662f61ce073ea221/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 3/3 [00:00<00:00, 984.81it/s]\n",
      "Using custom data configuration yangezheng--EXIST2021-d1ae4c0aa3225b46\n",
      "Found cached dataset parquet (/home/jw/.cache/huggingface/datasets/yangezheng___parquet/yangezheng--EXIST2021-d1ae4c0aa3225b46/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 3/3 [00:00<00:00, 938.81it/s]\n"
     ]
    }
   ],
   "source": [
    "tum_dataset = load_dataset(\"yangezheng/tum-nlp-sexism-socialmedia-balanced\")\n",
    "lidia_dataset = load_dataset(\"yangezheng/lidiapierre-fr_sexism_labelled\")\n",
    "cmsb_dataset = load_dataset(\"yangezheng/CMSB\")\n",
    "swsr_comment_dataset = load_dataset(\"yangezheng/SWSR-SexComment\")\n",
    "swsr_weibo_dataset = load_dataset(\"yangezheng/SWSR-SexWeibo\")\n",
    "exist_dataset = load_dataset(\"yangezheng/EXIST2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidia_dataset = lidia_dataset.remove_columns(\"fr_sentences\")\n",
    "cmsb_dataset = cmsb_dataset.remove_columns(\"toxicity\")\n",
    "swsr_comment_dataset = swsr_comment_dataset.remove_columns(\"text_cn\")\n",
    "swsr_comment_dataset = swsr_comment_dataset.remove_columns(\"category\")\n",
    "swsr_comment_dataset = swsr_comment_dataset.remove_columns(\"target\")\n",
    "swsr_weibo_dataset = swsr_weibo_dataset.remove_columns(\"text_cn\")\n",
    "swsr_weibo_dataset = swsr_weibo_dataset.remove_columns(\"keyword\")\n",
    "exist_dataset = exist_dataset.remove_columns(\"text_original\")\n",
    "exist_dataset = exist_dataset.remove_columns(\"task2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label_sexist'],\n",
       "    num_rows: 41335\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = concatenate_datasets([tum_dataset[\"train\"], lidia_dataset[\"train\"], cmsb_dataset[\"train\"], swsr_comment_dataset[\"train\"], swsr_weibo_dataset[\"train\"], exist_dataset[\"train\"]])\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label_sexist'],\n",
       "    num_rows: 5368\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset = concatenate_datasets([tum_dataset[\"validation\"], lidia_dataset[\"validation\"], cmsb_dataset[\"validation\"], swsr_comment_dataset[\"validation\"], swsr_weibo_dataset[\"validation\"], exist_dataset[\"validation\"]])\n",
    "validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label_sexist'],\n",
       "    num_rows: 8730\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = concatenate_datasets([tum_dataset[\"test\"], lidia_dataset[\"test\"], cmsb_dataset[\"test\"], swsr_comment_dataset[\"test\"], swsr_weibo_dataset[\"test\"], exist_dataset[\"test\"]])\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_sexist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ITALY - RAPE JIHAD days after horrific gang-ra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I dont take you places because I wanna be frie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[USER] This is actually the most worrying bit ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You mother fucking piece of trash stupid fucki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes, this will certainly bring down Trump.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41330</th>\n",
       "      <td>The pain is not in quarantine.Ref. Advance of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41331</th>\n",
       "      <td>You enter social networks and in the midst of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41332</th>\n",
       "      <td>All my support for @gabrielsotoMEX, who is the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41333</th>\n",
       "      <td>When farts are going to understand that we don...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41334</th>\n",
       "      <td>@JoshHarris91 @unitedwarrior6 @Kevwafc19701 @F...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41335 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label_sexist\n",
       "0      ITALY - RAPE JIHAD days after horrific gang-ra...             0\n",
       "1      I dont take you places because I wanna be frie...             1\n",
       "2      [USER] This is actually the most worrying bit ...             1\n",
       "3      You mother fucking piece of trash stupid fucki...             1\n",
       "4             Yes, this will certainly bring down Trump.             0\n",
       "...                                                  ...           ...\n",
       "41330  The pain is not in quarantine.Ref. Advance of ...             0\n",
       "41331  You enter social networks and in the midst of ...             1\n",
       "41332  All my support for @gabrielsotoMEX, who is the...             1\n",
       "41333  When farts are going to understand that we don...             1\n",
       "41334  @JoshHarris91 @unitedwarrior6 @Kevwafc19701 @F...             0\n",
       "\n",
       "[41335 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_dataset = train_dataset.to_pandas()\n",
    "pandas_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_sexist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ITALY - RAPE JIHAD days after horrific gang-ra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I dont take you places because I wanna be frie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[USER] This is actually the most worrying bit ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You mother fucking piece of trash stupid fucki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes, this will certainly bring down Trump.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41330</th>\n",
       "      <td>The pain is not in quarantine.Ref. Advance of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41331</th>\n",
       "      <td>You enter social networks and in the midst of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41332</th>\n",
       "      <td>All my support for @gabrielsotoMEX, who is the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41333</th>\n",
       "      <td>When farts are going to understand that we don...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41334</th>\n",
       "      <td>@JoshHarris91 @unitedwarrior6 @Kevwafc19701 @F...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41333 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label_sexist\n",
       "0      ITALY - RAPE JIHAD days after horrific gang-ra...             0\n",
       "1      I dont take you places because I wanna be frie...             1\n",
       "2      [USER] This is actually the most worrying bit ...             1\n",
       "3      You mother fucking piece of trash stupid fucki...             1\n",
       "4             Yes, this will certainly bring down Trump.             0\n",
       "...                                                  ...           ...\n",
       "41330  The pain is not in quarantine.Ref. Advance of ...             0\n",
       "41331  You enter social networks and in the midst of ...             1\n",
       "41332  All my support for @gabrielsotoMEX, who is the...             1\n",
       "41333  When farts are going to understand that we don...             1\n",
       "41334  @JoshHarris91 @unitedwarrior6 @Kevwafc19701 @F...             0\n",
       "\n",
       "[41333 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_dataset = pandas_dataset.dropna()\n",
    "pandas_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label_sexist', '__index_level_0__'],\n",
       "    num_rows: 41333\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(pandas_dataset)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:05<00:00,  8.01ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label_sexist', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 41333\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(lambda e: tokenizer(e[\"text\"], padding=\"max_length\", truncation=True), batched=True)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  9.12ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label_sexist', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 5368\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset = validation_dataset.map(lambda e: tokenizer(e[\"text\"], padding=\"max_length\", truncation=True), batched=True)\n",
    "validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\", save_strategy=\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.rename_column(\"label_sexist\", \"label\")\n",
    "validation_dataset = validation_dataset.rename_column(\"label_sexist\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 41333\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 5368\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15501' max='15501' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15501/15501 37:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.427000</td>\n",
       "      <td>0.442673</td>\n",
       "      <td>0.817809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.377100</td>\n",
       "      <td>0.417789</td>\n",
       "      <td>0.820976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.258800</td>\n",
       "      <td>0.609550</td>\n",
       "      <td>0.823584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/jw/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin: 100%|██████████| 540M/540M [35:08<00:00, 256kB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/jinx2321/bertweet-base-sexism/commit/3e4d2a1133fbeead832bbc5c02a17e609cf1882c', commit_message='Upload RobertaForSequenceClassification', commit_description='', oid='3e4d2a1133fbeead832bbc5c02a17e609cf1882c', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    \n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "login()\n",
    "model.push_to_hub(\"bertweet-base-sexism\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7943871706758304, 'recall': 0.7536193735193472, 'precision': 0.7692101020956476, 'f1': 0.7613349288658422, 'total_time_in_seconds': 47.21233773799031, 'samples_per_second': 184.90929316925644, 'latency_in_seconds': 0.005408057014660975}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "from evaluate import evaluator\n",
    "\n",
    "task_evaluator = evaluator(\"text-classification\")\n",
    "results = task_evaluator.compute(\n",
    "    model_or_pipeline=model,\n",
    "    data=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    metric=evaluate.combine([\"accuracy\", \"recall\", \"precision\", \"f1\"]),\n",
    "    label_column=\"label_sexist\",\n",
    "    label_mapping={\"LABEL_0\": 0, \"LABEL_1\": 1}\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading config.json: 100%|██████████| 819/819 [00:00<00:00, 5.44MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 540M/540M [01:24<00:00, 6.36MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7581901489117984, 'recall': 0.7959989470913398, 'precision': 0.6935779816513762, 'f1': 0.741267312170609, 'total_time_in_seconds': 46.21313320600893, 'samples_per_second': 188.90733854991828, 'latency_in_seconds': 0.0052936005963355025}\n"
     ]
    }
   ],
   "source": [
    "no_eval = AutoModelForSequenceClassification.from_pretrained(\"jinx2321/no-eval\").to(\"cuda\")\n",
    "\n",
    "task_evaluator = evaluator(\"text-classification\")\n",
    "results = task_evaluator.compute(\n",
    "    model_or_pipeline=no_eval,\n",
    "    data=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    metric=evaluate.combine([\"accuracy\", \"recall\", \"precision\", \"f1\"]),\n",
    "    label_column=\"label_sexist\",\n",
    "    label_mapping={\"LABEL_0\": 0, \"LABEL_1\": 1}\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 955/955 [00:00<00:00, 6.66MB/s]\n",
      "Using custom data configuration lidiapierre--fr_sexism_labelled-e5562c95e5b2c5a9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /home/jw/.cache/huggingface/datasets/lidiapierre___parquet/lidiapierre--fr_sexism_labelled-e5562c95e5b2c5a9/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 120k/120k [00:00<00:00, 4.37MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 1311.95it/s]\n",
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/jw/.cache/huggingface/datasets/lidiapierre___parquet/lidiapierre--fr_sexism_labelled-e5562c95e5b2c5a9/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1038.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9155672823218998, 'recall': 0.8846153846153846, 'precision': 0.9583333333333334, 'f1': 0.9199999999999999, 'total_time_in_seconds': 6.077365921024466, 'samples_per_second': 187.0876321708032, 'latency_in_seconds': 0.005345088760795485}\n"
     ]
    }
   ],
   "source": [
    "work_dataset = load_dataset(\"lidiapierre/fr_sexism_labelled\")[\"train\"]\n",
    "\n",
    "task_evaluator = evaluator(\"text-classification\")\n",
    "work_results = task_evaluator.compute(\n",
    "    model_or_pipeline=model,\n",
    "    data=work_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    metric=evaluate.combine([\"accuracy\", \"recall\", \"precision\", \"f1\"]),\n",
    "    input_column=\"Sentences\",\n",
    "    label_column=\"Label\",\n",
    "    label_mapping={\"LABEL_0\": 0, \"LABEL_1\": 1}\n",
    ")\n",
    "\n",
    "print(work_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
