{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad95ba0e5dd470384f3e2a0c9cee29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/6977 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65428f878664422fa492b6104624a3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/4368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "EXIST_train = load_dataset(\"csv\", data_files=\"EXIST2021_training.tsv\", sep=\"\\t\")['train']\n",
    "EXIST_test = load_dataset(\"csv\", data_files=\"EXIST2021_test_labeled.tsv\", sep=\"\\t\")['train']\n",
    "\n",
    "EXIST_train = EXIST_train.remove_columns(['test_case', 'id', 'source', 'language'])\n",
    "EXIST_test = EXIST_test.remove_columns(['test_case', 'id', 'source', 'language'])\n",
    "\n",
    "EXIST_train = EXIST_train.rename_column('task1','label_sexist')\n",
    "EXIST_test = EXIST_test.rename_column('task1','label_sexist')\n",
    "\n",
    "EXIST_train = EXIST_train.class_encode_column(\"label_sexist\")\n",
    "EXIST_test = EXIST_test.class_encode_column(\"label_sexist\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Pennsylvania State Rep horrifies with opening prayermooslime politican Movita Johnson-Harrell offended by the word 'Jesus' and 'God'.In a mainly Christian country praying to God/Jesus - what a scandal /sarc. It's the well-known mooslime strategy: playing the victim card and make demands.https://truepundit.com/pennsylvania-state-rep-horrifies-democrats-with-opening-prayer-at-the-name-of-jesus-every-knee-will-bow/\",\n",
       " 'label_sexist': 0,\n",
       " 'task2': 'non-sexist'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXIST_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecef5082f2e64dc7bf4b708d138428db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/6977 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label_sexist', 'task2'],\n",
      "        num_rows: 5581\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label_sexist', 'task2'],\n",
      "        num_rows: 1396\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label_sexist', 'task2'],\n",
      "        num_rows: 6977\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import ClassLabel\n",
    "\n",
    "new_features = EXIST_train.features.copy()\n",
    "new_features['label_sexist'] = ClassLabel(names=[\"not sexist\", \"sexist\"])\n",
    "EXIST_train = EXIST_train.cast(new_features)\n",
    "EXIST_test = EXIST_train.cast(new_features)\n",
    "\n",
    "## Split the dataset\n",
    "\n",
    "split_dataset = EXIST_train.train_test_split(0.2,stratify_by_column='label_sexist')\n",
    "train_dataset = split_dataset['train']\n",
    "validation_dataset = split_dataset['test']\n",
    "test_dataset = EXIST_test\n",
    "\n",
    "## combine the dataset\n",
    "\n",
    "from datasets import DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': validation_dataset,\n",
    "    'test': test_dataset,\n",
    "})\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token read successfully\n",
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/yzheng/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a900889cfbbc4ab9b0fdd0dc36af8821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954a4b92bdcd45748284d084fba53a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeffba0ebb954a91934cf9c97ddec83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa37c7d057649d2920044af2a82c833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2047cfd934c548babe185a0f1797fc50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68781554a4d547df9a38561c8cc7d231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "## Upload the dataset\n",
    "\n",
    "import json\n",
    "\n",
    "file_path = \"credentials.json\"\n",
    "\n",
    "with open(file_path, 'r') as json_file:\n",
    "    token_data = json.load(json_file)\n",
    "\n",
    "token = token_data.get(\"huggingface_token\")\n",
    "if token:\n",
    "    print(f\"Token read successfully\")\n",
    "else:\n",
    "    print(\"Error: Token not found in the JSON file.\")\n",
    "    \n",
    "import huggingface_hub\n",
    "\n",
    "huggingface_hub.login(token)\n",
    "\n",
    "dataset_dict.push_to_hub(\"yangezheng/EXIST2021\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
